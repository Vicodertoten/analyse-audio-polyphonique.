# Analyse audio polyphonique : une bo√Æte √† outils pour la recherche

Ce projet contient le code source du pipeline d'analyse audio automatis√©e d√©velopp√© dans le cadre du m√©moire de Master "Analyse de la mise en forme sonore du podcast ‚ÄòTacapt√©‚Äô" (V. Ryelandt, IHECS, 2025).

L'objectif de ce pipeline n'est pas de remplacer l'analyse qualitative humaine (*close listening*), qui reste au c≈ìur de la m√©thodologie du m√©moire, mais de servir d'outil d'exploration prospective pour :
1.  √âvaluer les capacit√©s et les limites des mod√®les actuels (Whisper, Pyannote, YAMNet) sur un objet sonore complexe.
2.  Documenter une m√©thode d'analyse polyphonique reproductible, en extrayant et croisant plusieurs couches d'information (parole, musique, bruitages, silences).
3.  Fournir une base de donn√©es et de code transparente pour de futures recherches.

## Fonctionnalit√©s principales

Le pipeline (`main.py`) automatise les t√¢ches suivantes :
* **Pr√©traitement audio :** Conversion automatique des fichiers en format WAV mono 16kHz pour standardiser l'analyse.
* **Extraction de caract√©ristiques :** Calcul du volume (RMS), du taux de passage par z√©ro (ZCR) et des MFCCs par seconde, avec un seuil de d√©tection de silence adaptatif.
* **Transcription :** Transcription int√©grale de l'audio via le mod√®le `medium` de Whisper.
* **Diarisation :** Identification des locuteurs avec `pyannote/speaker-diarization-3.1`, avec une distinction entre les segments de parole unique et les segments de parole superpos√©e.
* **Classification sonore :** Identification multi-label d'√©v√©nements sonores (Musique, Bruitages, etc.) via le mod√®le YAMNet.
* **Synth√®se polyphonique :** Cr√©ation d'une timeline unifi√©e qui, pour chaque pas de temps, indique quels locuteurs parlent, quels sons sont pr√©sents et si le moment est silencieux.
* **Calcul de statistiques :** G√©n√©ration de statistiques sur le temps de parole, le d√©bit, et la dynamique d'interaction (*turn-taking*).
* **Export complet :** Sauvegarde de toutes les donn√©es et statistiques dans un fichier Excel multi-feuilles et g√©n√©ration de visualisations graphiques (timelines, histogrammes).

## Installation

### 1. Pr√©requis syst√®me
* **Python (3.8 ou sup√©rieur)**
* **FFmpeg :** Cet outil est **essentiel** pour la conversion audio. Il doit √™tre install√© sur votre syst√®me et accessible depuis votre terminal. Instructions sur [ffmpeg.org](https://ffmpeg.org/download.html).

### 2. Cloner le d√©p√¥t
Clonez ce d√©p√¥t sur votre machine locale :
```bash
git clone [https://github.com/votre-nom-utilisateur/memoire-analyse-sonore-2025.git](https://github.com/votre-nom-utilisateur/memoire-analyse-sonore-2025.git)
cd memoire-analyse-sonore-2025
```

### 3. Mod√®le YAMNet local
Ce projet utilise une impl√©mentation locale du mod√®le YAMNet. Assurez-vous que le r√©pertoire `yamnet/` contenant les fichiers du mod√®le est pr√©sent √† la racine du projet, tel que fourni.

### 4. Cr√©er un environnement virtuel et installer les d√©pendances
Il est fortement recommand√© d'utiliser un environnement virtuel.
```bash
# Cr√©er un environnement virtuel
python -m venv venv

# Activer l'environnement
# Sur Windows:
venv\Scripts\activate
# Sur macOS/Linux:
source venv/bin/activate

# Installer les biblioth√®ques Python requises
pip install -r requirements.txt
```

### 5. Configurer les variables d'environnement
La diarisation via Pyannote n√©cessite une authentification aupr√®s de Hugging Face.
1.  Cr√©ez un fichier nomm√© `.env` √† la racine du projet.
2.  Ajoutez-y votre token d'acc√®s Hugging Face :
    ```
    HUGGINGFACE_TOKEN="hf_VotreTokenIci"
    ```
Vous devez accepter les conditions d'utilisation des mod√®les `pyannote/speaker-diarization-3.1` et `pyannote/segmentation-3.0` sur le Hugging Face Hub.

## Utilisation

Le script principal s'ex√©cute en ligne de commande.

**Option 1 : Passer le chemin du fichier en argument**
```bash
python main.py "chemin/vers/votre/fichier.mp3"
```

**Option 2 : Mode interactif**
Si aucun argument n'est fourni, le script vous demandera d'entrer le chemin du fichier.
```bash
python main.py
# üü¢ Entrez le chemin du fichier audio : ...
```

## Structure du projet

```
.
‚îú‚îÄ‚îÄ modules/                # Modules Python contenant la logique de l'analyse
‚îÇ   ‚îú‚îÄ‚îÄ audio_loader.py
‚îÇ   ‚îú‚îÄ‚îÄ transcription.py
‚îÇ   ‚îú‚îÄ‚îÄ diarization_pyannote.py
‚îÇ   ‚îú‚îÄ‚îÄ yamnet_analysis.py
‚îÇ   ‚îú‚îÄ‚îÄ analysis_utils.py
‚îÇ   ‚îî‚îÄ‚îÄ exporter.py
‚îú‚îÄ‚îÄ yamnet/                   # Fichiers du mod√®le YAMNet local
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ main.py                 # Script principal pour lancer le pipeline
‚îú‚îÄ‚îÄ requirements.txt        # Liste des d√©pendances Python
‚îú‚îÄ‚îÄ .env                    # Fichier pour les variables d'environnement (√† cr√©er)
‚îî‚îÄ‚îÄ README.md               # Ce fichier
```

Une fois l'analyse termin√©e, un r√©pertoire `r√©sultats_analyse/` sera cr√©√© avec un sous-dossier portant le nom de votre fichier audio, contenant le rapport Excel et tous les graphiques.

## Licence
Ce projet est mis √† disposition sous la licence MIT. Voir le fichier `LICENSE` pour plus de d√©tails.
