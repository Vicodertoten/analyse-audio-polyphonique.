# modules/audio_loader.py
import pandas as pd
import librosa
import numpy as np
import os
import subprocess
import sys
from modules.analysis_utils import format_time_ms

def convert_to_wav_16k_mono(input_path):
    base, _ = os.path.splitext(input_path)
    output_path = base + "_converted.wav"
    if not os.path.exists(output_path): # V√©rifier si le fichier converti existe d√©j√†
        cmd = [
            "ffmpeg", "-y", # -y pour √©craser sans demander
            "-i", input_path,
            "-ac", "1",        # mono
            "-ar", "16000",    # 16kHz
            output_path
        ]
        print("üîÑ Conversion du fichier audio en WAV mono 16kHz...")
        try:
            subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            print(f"‚úÖ Fichier converti : {output_path}")
        except subprocess.CalledProcessError as e:
            print(f"‚ùå Erreur lors de la conversion avec ffmpeg : {e}")
            # G√©rer l'erreur, peut-√™tre sortir ou retourner None
            return None # ou sys.exit(1)
        except FileNotFoundError:
            print("‚ùå Erreur: ffmpeg n'est pas install√© ou n'est pas dans le PATH.")
            return None # ou sys.exit(1)
    else:
        print(f"‚òëÔ∏è Fichier converti existant trouv√© : {output_path}")
    return output_path

def select_audio_file():
    if len(sys.argv) < 2:
        filename_input = input("üü¢ Entrez le chemin du fichier audio : ").strip().strip("'").strip('"')
    else:
        filename_input = sys.argv[1]

    if not os.path.isfile(filename_input):
        print(f"‚ùå Fichier introuvable : {filename_input}")
        sys.exit(1)

    # Le fichier trait√© sera le WAV, m√™me si l'entr√©e est un MP3
    filepath_for_processing = filename_input
    if filename_input.lower().endswith(".mp3"):
        filepath_for_processing = convert_to_wav_16k_mono(filename_input)
        if filepath_for_processing is None: # √âchec de la conversion
            print("‚ùå Impossible de traiter le fichier audio apr√®s √©chec de conversion.")
            sys.exit(1)
            
    print(f"‚úÖ Fichier s√©lectionn√© pour traitement : {filepath_for_processing}")
    
    # Charger les donn√©es audio √† partir du fichier trait√© (WAV)
    try:
        audio_samples, sample_rate = librosa.load(filepath_for_processing, sr=None) # sr=None pour charger avec le SR natif (devrait √™tre 16k)
        if sample_rate != 16000:
            print(f"‚ö†Ô∏è Attention: Le taux d'√©chantillonnage est de {sample_rate}Hz et non 16000Hz comme attendu apr√®s conversion.")
            # Vous pourriez forcer le r√©√©chantillonnage ici si n√©cessaire, mais la conversion devrait s'en charger.
            # audio_samples = librosa.resample(audio_samples, orig_sr=sample_rate, target_sr=16000)
            # sample_rate = 16000

    except Exception as e:
        print(f"‚ùå Erreur lors du chargement du fichier audio avec Librosa : {e}")
        sys.exit(1)
        
    return filepath_for_processing, audio_samples, sample_rate

def get_audio_duration(filepath: str) -> float:
    """Retourne la dur√©e d'un fichier audio en secondes."""
    try:
        return librosa.get_duration(path=filepath)
    except Exception as e:
        print(f"‚ùå Impossible d'obtenir la dur√©e pour {filepath}: {e}")
        return 0.0

def extract_features(
    audio_samples: np.ndarray, 
    sample_rate: int, 
    fixed_silence_threshold: float = None, # Seuil fixe optionnel
    adaptive_percentile: int = 10,        # Percentile pour estimer le plancher de son actif
    adaptive_factor: float = 0.8          # Facteur multiplicatif pour le seuil adaptatif
    ):
    """
    Extrait les caract√©ristiques audio par fen√™tres de 1 seconde.
    Permet un seuil de silence fixe ou adaptatif.

    Args:
        audio_samples (np.ndarray): Les √©chantillons audio.
        sample_rate (int): Le taux d'√©chantillonnage.
        fixed_silence_threshold (float, optional): Si fourni, utilise ce seuil RMS fixe.
                                                   Sinon, un seuil adaptatif est calcul√©.
        adaptive_percentile (int): Percentile (0-100) des RMS non nuls √† utiliser comme
                                   niveau de r√©f√©rence pour le seuil adaptatif.
        adaptive_factor (float): Facteur √† appliquer au niveau de r√©f√©rence pour obtenir
                                 le seuil adaptatif (ex: 0.5 signifie 50% du niveau de r√©f√©rence).
    Returns:
        pd.DataFrame
    """
    frame_duration_sec = 1.0
    hop_length_samples = int(frame_duration_sec * sample_rate)

    num_frames_total = int(np.floor(len(audio_samples) / hop_length_samples))
    
    raw_features_data = [] # Pour stocker les dictionnaires avant de d√©terminer le seuil adaptatif

    if num_frames_total == 0: # Audio trop court
        print("Avertissement: Audio trop court pour extraire des features avec une fen√™tre de 1s.")
        columns = ['start', 'end', 'rms', 'zcr', 'is_silence'] + [f'mfcc_{j+1}' for j in range(13)]
        return pd.DataFrame(columns=columns)

    for i in range(num_frames_total):
        start_sample = i * hop_length_samples
        end_sample = start_sample + hop_length_samples
        frame = audio_samples[start_sample:end_sample]

        if len(frame) == 0:
            continue

        start_time_sec = start_sample / sample_rate
        end_time_sec = end_sample / sample_rate
        
        rms_value = np.sqrt(np.mean(frame**2)) # Calcul RMS simple
        zcr_value = np.mean(librosa.feature.zero_crossing_rate(y=frame, frame_length=len(frame), hop_length=len(frame)+1)[0])
        mfccs = librosa.feature.mfcc(
            y=frame,
            sr=sample_rate,
            n_mfcc=13,
            n_fft=2048,
            hop_length=hop_length_samples // 4 if hop_length_samples // 4 > 0 else 512
        ) # hop_length plus petit pour MFCC
        mfcc_mean_values = np.mean(mfccs, axis=1)
        
        row_data = {
            'start': start_time_sec,
            'end': end_time_sec,
            'rms': rms_value,
            'zcr': zcr_value,
            # 'is_silence' sera ajout√© apr√®s le calcul du seuil
        }
        for j in range(13):
            row_data[f'mfcc_{j+1}'] = mfcc_mean_values[j]
        
        raw_features_data.append(row_data)

    df_raw_features = pd.DataFrame(raw_features_data)

    # D√©termination du seuil de silence
    actual_silence_threshold = 0.0 # Initialisation
    if fixed_silence_threshold is not None:
        actual_silence_threshold = fixed_silence_threshold
        print(f"‚ÑπÔ∏è Utilisation du seuil de silence fixe : {actual_silence_threshold:.4f}")
    else:
        # Calcul du seuil adaptatif
        all_rms_values = df_raw_features["rms"][df_raw_features["rms"] > 1e-6] # Ignorer les RMS quasi nuls
        if not all_rms_values.empty:
            # Niveau de r√©f√©rence bas√© sur le percentile des RMS significatifs
            reference_rms_level = np.percentile(all_rms_values, adaptive_percentile)
            actual_silence_threshold = reference_rms_level * adaptive_factor
            print(f"‚ÑπÔ∏è Calcul du seuil de silence adaptatif : {actual_silence_threshold:.4f} "
                  f"(bas√© sur le {adaptive_percentile}e percentile = {reference_rms_level:.4f} * facteur {adaptive_factor})")
        else:
            # Fallback si l'audio est compl√®tement silencieux ou si tous les RMS sont trop bas
            actual_silence_threshold = 0.01 # Valeur de fallback
            print(f"‚ö†Ô∏è Impossible de calculer le seuil adaptatif (peu de son d√©tect√©), "
                  f"utilisation du seuil de fallback : {actual_silence_threshold:.4f}")

    # Appliquer le seuil pour d√©terminer 'is_silence'
    df_raw_features["is_silence"] = df_raw_features["rms"] < actual_silence_threshold

    if not df_raw_features.empty:
     df_raw_features['start_ms'] = df_raw_features['start'].apply(format_time_ms)
     df_raw_features['end_ms'] = df_raw_features['end'].apply(format_time_ms)

        
    return df_raw_features